{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d4ee01-f9cd-4858-8c5b-bab99c5ad5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/va0831/slr/end_slr/lib64/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/va0831/Projects/FlowMatchingMnist\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e14a303-7af8-4008-bfdf-bdcb9e42f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional_mnist_diffusion_flow.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- Configuración ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 128\n",
    "timesteps = 100\n",
    "img_shape = (1, 28, 28)\n",
    "os.makedirs(\"outputs/diffusion\", exist_ok=True)\n",
    "os.makedirs(\"outputs/flow_matching\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879acfe1-48f9-4a8b-8649-e04701bfa85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x * 2 - 1)\n",
    "])\n",
    "dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40661c4f-b138-4e1a-a5ad-45f579514160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modelos ---\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, 64), nn.ReLU(), nn.Linear(64, 64)\n",
    "        )\n",
    "        self.label_embed = nn.Embedding(10, 64)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1 + 1 + 1, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, y):\n",
    "        t_embed = self.time_embed(t.view(-1, 1).float())\n",
    "        y_embed = self.label_embed(y)\n",
    "        cond = t_embed + y_embed\n",
    "        cond_img = cond.view(-1, cond.size(1), 1, 1).expand(-1, cond.size(1), 28, 28)\n",
    "        x = torch.cat([x, cond_img[:, :1], cond_img[:, 1:2]], dim=1)  # fake 2-ch cond\n",
    "        return self.net(x)\n",
    "\n",
    "# --- Entrenamiento Diffusion ---\n",
    "def train_diffusion():\n",
    "    #model = nn.DataParallel(DiffusionModel(), device_ids=[0,1,2,3,4,5]).to(device)\n",
    "    model = DiffusionModel().to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    betas = torch.linspace(1e-4, 0.02, timesteps).to(device)\n",
    "    alphas = 1 - betas\n",
    "    alpha_hat = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        pbar = tqdm(dataloader, desc=f\"[Diffusion {epoch}]\", leave=False, ncols=80)\n",
    "        for x, y in pbar:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            t = torch.randint(0, timesteps, (x.size(0),), device=device)\n",
    "            a_hat = alpha_hat[t].view(-1, 1, 1, 1)\n",
    "            noise = torch.randn_like(x)\n",
    "            x_t = a_hat.sqrt() * x + (1 - a_hat).sqrt() * noise\n",
    "\n",
    "            noise_pred = model(x_t, t, y)\n",
    "            mse = F.mse_loss(noise_pred, noise)\n",
    "            norm_pred = F.log_softmax(noise_pred.view(noise_pred.size(0), -1), dim=1)\n",
    "            norm_true = F.softmax(noise.view(noise.size(0), -1), dim=1)\n",
    "            kl = F.kl_div(norm_pred, norm_true, reduction='batchmean')\n",
    "            loss = mse + 0.1 * kl\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            if epoch == 0 and pbar.n < 5:\n",
    "                print(\"x_t:\", x_t.min().item(), x_t.max().item())\n",
    "                print(\"noise_pred:\", noise_pred.min().item(), noise_pred.max().item())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            generate_diffusion(9, model=model, save_path=f\"outputs/diffusion/sample_epoch{epoch+1}.png\")\n",
    "            torch.save(model.state_dict(), \"outputs/diffusion/diffusion_model.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"outputs/diffusion/diffusion_model.pth\")\n",
    "\n",
    "# --- Generación Diffusion Condicional ---\n",
    "@torch.no_grad()\n",
    "def generate_diffusion(label, model=None, save_path=None, show=False):\n",
    "    if model is None:\n",
    "        #model = nn.DataParallel(DiffusionModel(), device_ids=[0,1,2,3,4,5]).to(device)\n",
    "        model = DiffusionModel().to(device)\n",
    "        model.load_state_dict(torch.load(\"outputs/diffusion/diffusion_model.pth\"))\n",
    "        model.eval()\n",
    "\n",
    "    x = torch.randn(64, *img_shape).to(device)\n",
    "    y = torch.full((64,), label, dtype=torch.long, device=device)\n",
    "\n",
    "    betas = torch.linspace(1e-4, 0.02, timesteps).to(device)\n",
    "    alphas = 1 - betas\n",
    "    alpha_hat = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "    for t in reversed(range(timesteps)):\n",
    "        t_batch = torch.full((x.size(0),), t, device=device, dtype=torch.long)\n",
    "        eps_pred = model(x, t_batch, y)\n",
    "        alpha_t = alphas[t]\n",
    "        alpha_bar_t = alpha_hat[t]\n",
    "        x0_pred = (x - (1 - alpha_bar_t).sqrt() * eps_pred) / alpha_bar_t.sqrt()\n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        x = alpha_t.sqrt() * x0_pred + (1 - alpha_t).sqrt() * noise\n",
    "\n",
    "    img = (x + 1) / 2\n",
    "    utils.save_image(img, save_path or f\"outputs/diffusion/diffusion_gen_{label}.png\", nrow=8)\n",
    "    if show:\n",
    "        plt.imshow(img[0].cpu().squeeze().numpy(), cmap='gray')\n",
    "        plt.title(f'Generated {label}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# --- Ejecutar ---\n",
    "# train_diffusion()\n",
    "# generate_diffusion(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c1928-d54e-4687-9ca3-a30de46542e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Diffusion 807]:  15%|█▊          | 69/469 [00:01<00:06, 60.06it/s, loss=0.0722]"
     ]
    }
   ],
   "source": [
    "train_diffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a62a9e-45db-42d3-b414-3b15a1753f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57367495-e51d-4515-9fd4-2d697a9c5fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701bbe63-6efd-4304-b7af-d6068b00f33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f94e7-3cde-45ef-8208-75effeaf50eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a77a8-bf66-46e3-b544-2e965118814a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
